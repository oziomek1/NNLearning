{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# single hidden layer NN model -> multi-layer perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "(X_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# single hidden layer NN model -> multi-layer perceptron\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "num_classes = 10\n",
    "num_pixels = 784\n",
    "X_train = X_train.reshape(X_train.shape[0], num_pixels).astype('float32')\n",
    "x_test = x_test.reshape(x_test.shape[0], num_pixels).astype('float32')\n",
    "\n",
    "# normalize grayscale 0-255 to 0-1\n",
    "X_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "#make onehot vector labels\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]\n",
    "\n",
    "# baseline model\n",
    "def baseline():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(num_pixels, input_dim=num_pixels, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(num_classes, kernel_initializer='normal', activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:2885: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:1349: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.2797 - acc: 0.9208 - val_loss: 0.1413 - val_acc: 0.9576\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.1116 - acc: 0.9679 - val_loss: 0.0919 - val_acc: 0.9708\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0717 - acc: 0.9797 - val_loss: 0.0778 - val_acc: 0.9775\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.0503 - acc: 0.9855 - val_loss: 0.0748 - val_acc: 0.9765\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.0373 - acc: 0.9892 - val_loss: 0.0676 - val_acc: 0.9791\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.0267 - acc: 0.9926 - val_loss: 0.0625 - val_acc: 0.9810\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.0205 - acc: 0.9947 - val_loss: 0.0620 - val_acc: 0.9803\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.0139 - acc: 0.9971 - val_loss: 0.0627 - val_acc: 0.9803\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.0107 - acc: 0.9978 - val_loss: 0.0578 - val_acc: 0.9818\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.0079 - acc: 0.9986 - val_loss: 0.0589 - val_acc: 0.9805\n",
      "Baseline error 1.95%\n",
      "Test accuracy: 0.05885595259328547\n",
      "Test loss 0.9805\n"
     ]
    }
   ],
   "source": [
    "model = baseline()\n",
    "\n",
    "model.fit(X_train, y_train, validation_data=(x_test, y_test), epochs=10, batch_size=200, verbose=1)\n",
    "\n",
    "scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Baseline error %.2f%%' % (100-scores[1]*100))\n",
    "print('Test accuracy:', scores[0])\n",
    "print('Test loss', scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional NN (1 layer) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import to_categorical\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "K.set_image_dim_ordering('th')\n",
    "\n",
    "(X_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "num_classes = 10\n",
    "# 2D convolution = [pixels][width][height] (grayscale = 1 pixels layer, RGB = 3pixels layer etc)\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28).astype('float32')\n",
    "x_test = x_test.reshape(x_test.shape[0], 1, 28, 28).astype('float32')\n",
    "\n",
    "#normalize 0-255 to 0-1\n",
    "X_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "#one-hot\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def baseline_2():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (5, 5), input_shape=(1, 28, 28), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu')) # Conv2D features (32) * Poolind (2*2)\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.2457 - acc: 0.9298 - val_loss: 0.0717 - val_acc: 0.9783\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.0729 - acc: 0.9783 - val_loss: 0.0478 - val_acc: 0.9846\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.0523 - acc: 0.9844 - val_loss: 0.0394 - val_acc: 0.9875\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.0401 - acc: 0.9878 - val_loss: 0.0381 - val_acc: 0.9873\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.0335 - acc: 0.9894 - val_loss: 0.0456 - val_acc: 0.9862\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.0278 - acc: 0.9913 - val_loss: 0.0353 - val_acc: 0.9886\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.0226 - acc: 0.9926 - val_loss: 0.0331 - val_acc: 0.9894\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.0200 - acc: 0.9937 - val_loss: 0.0297 - val_acc: 0.9905\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.0167 - acc: 0.9946 - val_loss: 0.0377 - val_acc: 0.9887\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.0147 - acc: 0.9953 - val_loss: 0.0325 - val_acc: 0.9889\n",
      "CNN error: 1.11%\n",
      "Test accuracy: 0.032488281734345946\n",
      "Test loss 0.9889\n"
     ]
    }
   ],
   "source": [
    "model = baseline_2()\n",
    "\n",
    "model.fit(X_train, y_train, validation_data=(x_test, y_test), epochs=10, batch_size=200, verbose=1)\n",
    "\n",
    "scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('CNN error: %.2f%%' % (100-scores[1]*100))\n",
    "print('Test accuracy:', scores[0])\n",
    "print('Test loss', scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional NN (2 layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import to_categorical\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "K.set_image_dim_ordering('th')\n",
    "\n",
    "(X_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "num_classes = 10\n",
    "\n",
    "# 2D convolution = [pixels][width][height] (grayscale = 1 pixels layer, RGB = 3pixels layer etc)\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28).astype('float32')\n",
    "x_test = x_test.reshape(x_test.shape[0], 1, 28, 28).astype('float32')\n",
    "\n",
    "# normalize 0-255 grayscale to 0-1\n",
    "X_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# one-hot\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def baseline_3():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (5, 5), input_shape=(1, 28, 28), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(16, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.4329 - acc: 0.8627 - val_loss: 0.0809 - val_acc: 0.9749\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.1119 - acc: 0.9661 - val_loss: 0.0518 - val_acc: 0.9823\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.0809 - acc: 0.9747 - val_loss: 0.0392 - val_acc: 0.9874\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.0680 - acc: 0.9788 - val_loss: 0.0366 - val_acc: 0.9880\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.0574 - acc: 0.9824 - val_loss: 0.0280 - val_acc: 0.9903\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.0517 - acc: 0.9837 - val_loss: 0.0314 - val_acc: 0.9898\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.0450 - acc: 0.9860 - val_loss: 0.0285 - val_acc: 0.9909\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.0411 - acc: 0.9866 - val_loss: 0.0266 - val_acc: 0.9910\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.0376 - acc: 0.9883 - val_loss: 0.0238 - val_acc: 0.9929\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.0357 - acc: 0.9888 - val_loss: 0.0242 - val_acc: 0.9911\n",
      "Second CNN error: 0.89%\n",
      "Test accuracy: 0.024181631811166882\n",
      "Test loss 0.9911\n"
     ]
    }
   ],
   "source": [
    "model = baseline_3()\n",
    "\n",
    "model.fit(X_train, y_train, validation_data=(x_test, y_test), epochs=10, batch_size=200, verbose=1)\n",
    "\n",
    "scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "print('Second CNN error: %.2f%%' % (100-scores[1]*100))\n",
    "print('Test accuracy:', scores[0])\n",
    "print('Test loss', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
